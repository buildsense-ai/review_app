#!/usr/bin/env python3
"""
æ–‡æ¡£è®ºæ®æ”¯æŒåº¦è¯„ä¼°å™¨è¿è¡Œè„šæœ¬
ä½¿ç”¨æ–°çš„ä¸‰æ­¥éª¤æµç¨‹ï¼šæ£€æµ‹è®ºæ–­ â†’ websearch â†’ æŒ‰ç« èŠ‚ç”Ÿæˆ
"""

import sys
import os
from whole_document_pipeline import WholeDocumentPipeline

def main():
    """ä¸»å‡½æ•°"""
    
    # é»˜è®¤é…ç½®
    default_document = "final_markdown_merged_document_20250904_162736.md"
    default_max_claims = 15
    use_section_processing = True  # é»˜è®¤ä½¿ç”¨æ–°çš„ç« èŠ‚å¹¶è¡Œå¤„ç†
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) == 1:
        # æ— å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        document_path = default_document
        max_claims = default_max_claims
        print("ğŸ“‹ ä½¿ç”¨é»˜è®¤é…ç½®:")
        print(f"   - æ–‡æ¡£: {document_path}")
        print(f"   - æœ€å¤§è®ºæ–­æ•°: {max_claims}")
        print(f"   - å¤„ç†æ¨¡å¼: {'ç« èŠ‚å¹¶è¡Œå¤„ç†' if use_section_processing else 'æ•´ä½“æ–‡æ¡£å¤„ç†'}")
    elif len(sys.argv) == 2:
        # åªæä¾›æ–‡æ¡£è·¯å¾„
        document_path = sys.argv[1]
        max_claims = default_max_claims
    elif len(sys.argv) == 3:
        # æä¾›æ–‡æ¡£è·¯å¾„å’Œmax_claims
        document_path = sys.argv[1]
        max_claims = int(sys.argv[2])
    else:
        # æä¾›æ–‡æ¡£è·¯å¾„ã€max_claimså’Œå¤„ç†æ¨¡å¼
        document_path = sys.argv[1]
        max_claims = int(sys.argv[2])
        use_section_processing = sys.argv[3].lower() in ['true', '1', 'section', 'parallel']
    
    print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print("   python run_evaluator.py                                           # ä½¿ç”¨é»˜è®¤æ–‡æ¡£å’Œå‚æ•°")
    print("   python run_evaluator.py <document_path>                           # æŒ‡å®šæ–‡æ¡£ï¼Œä½¿ç”¨é»˜è®¤è®ºæ–­æ•°")
    print("   python run_evaluator.py <document_path> <max_claims>              # è‡ªå®šä¹‰è®ºæ–­æ•°")
    print("   python run_evaluator.py <document_path> <max_claims> <mode>       # å®Œå…¨è‡ªå®šä¹‰ (mode: true/false)")
    
    # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å­˜åœ¨
    if not os.path.exists(document_path):
        print(f"âŒ æ–‡æ¡£ä¸å­˜åœ¨: {document_path}")
        sys.exit(1)
    
    print("\nğŸš€ å¯åŠ¨æ–°çš„ä¸‰æ­¥éª¤æ–‡æ¡£è®ºæ®æ”¯æŒåº¦è¯„ä¼°å™¨")
    print(f"ğŸ“„ ç›®æ ‡æ–‡æ¡£: {document_path}")
    print(f"ğŸ“Š æœ€å¤§è®ºæ–­æ•°é‡: {max_claims}")
    print(f"ğŸ”„ å¤„ç†æ¨¡å¼: {'ç« èŠ‚å¹¶è¡Œå¤„ç† (æ¨è)' if use_section_processing else 'æ•´ä½“æ–‡æ¡£å¤„ç†'}")
    print("-" * 60)
    
    try:
        # åˆå§‹åŒ–æµæ°´çº¿
        pipeline = WholeDocumentPipeline()
        
        # è¿è¡Œæ–°çš„ä¸‰æ­¥éª¤è¯„ä¼°æµç¨‹
        print("ğŸ” æ­¥éª¤1: æ£€æµ‹ç¼ºä¹è¯æ®æ”¯æ’‘çš„è®ºæ–­...")
        print("ğŸŒ æ­¥éª¤2: WebSearchæœç´¢ç›¸å…³è¯æ®...")
        print("ğŸ“ æ­¥éª¤3: æŒ‰ç« èŠ‚å¹¶è¡Œç”Ÿæˆä¿®æ”¹æ–‡æ¡£...")
        print()
        
        result = pipeline.process_whole_document(
            document_path=document_path,
            max_claims=max_claims,
            max_search_results=10,
            use_section_based_processing=use_section_processing
        )
        
        # è¾“å‡ºç»“æœæ‘˜è¦
        if result['status'] == 'success':
            print("\nğŸ‰ æ–°çš„ä¸‰æ­¥éª¤è¯„ä¼°å®Œæˆï¼")
            print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
            stats = result.get('statistics', {})
            
            if use_section_processing:
                # ç« èŠ‚å¹¶è¡Œå¤„ç†æ¨¡å¼çš„ç»Ÿè®¡
                print(f"   - å¤„ç†ç« èŠ‚: {stats.get('total_sections', 0)} ä¸ª")
                print(f"   - æˆåŠŸç« èŠ‚: {stats.get('successful_sections', 0)} ä¸ª")
                print(f"   - æ£€æµ‹è®ºæ–­: {stats.get('total_claims_detected', 0)} ä¸ª")
                print(f"   - æœç´¢è¯æ®: {stats.get('total_evidence_sources', 0)} æ¡")
                print(f"   - å¤„ç†æ¨¡å¼: ç« èŠ‚å¹¶è¡Œå¤„ç† (max_workers=5)")
            else:
                # æ•´ä½“æ–‡æ¡£å¤„ç†æ¨¡å¼çš„ç»Ÿè®¡
                print(f"   - æ£€æµ‹è®ºæ–­: {stats.get('total_claims_detected', 0)} ä¸ª")
                print(f"   - æœç´¢è¯æ®: {stats.get('total_evidence_sources', 0)} æ¡")
                print(f"   - å¤„ç†æ¨¡å¼: æ•´ä½“æ–‡æ¡£å¤„ç†")
            
            print(f"   - å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.1f} ç§’")
            
            print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
            files = result.get('output_files', {})
            for file_type, file_path in files.items():
                print(f"   - {file_type}: {file_path}")
            
            if use_section_processing:
                print(f"\nâœ¨ æ–°åŠŸèƒ½äº®ç‚¹:")
                print(f"   - ğŸ” AIç²¾ç¡®æ£€æµ‹ç¼ºä¹è¯æ®çš„è®ºæ–­")
                print(f"   - ğŸŒ å¹¶è¡ŒWebSearchæœç´¢è¯æ®")
                print(f"   - ğŸ“ æŒ‰ç« èŠ‚å¹¶è¡Œç”Ÿæˆä¿®æ”¹ (5ä¸ªå·¥ä½œçº¿ç¨‹)")
                print(f"   - ğŸ“‹ JSONåˆå¹¶å™¨è¿½è¸ªæ‰€æœ‰ä¿®æ”¹")
                print(f"   - ğŸ¯ ç›´æ¥å‘Šè¯‰AIåœ¨å“ªé‡Œä¿®æ”¹ä»€ä¹ˆ")
            
        else:
            print(f"\nâŒ è¯„ä¼°å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ è¿è¡Œæ—¶é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()


#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†—ä½™åˆ†æå™¨ - è¯†åˆ«æ–‡æ¡£ä¸­çš„å†—ä½™å’Œé‡å¤å†…å®¹
"""

import os
import sys
import json
import logging
from typing import Dict, Any, List
from datetime import datetime
from openai import OpenAI

# å¯¼å…¥å…±äº«å¼‚å¸¸
sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), '..'))
from shared.exceptions import DocumentAnalysisError


class RedundancyAnalyzer:
    """å†—ä½™åˆ†æå™¨ - åˆ†ææ–‡æ¡£ä¸­çš„å†—ä½™å†…å®¹"""
    
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–å†—ä½™åˆ†æå™¨
        
        Args:
            api_key: OpenRouter APIå¯†é’¥
        """
        self.api_key = api_key or os.getenv("OPENROUTER_API_KEY")
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=self.api_key,
        )
        
        # å†—ä½™åˆ†ææç¤ºè¯æ¨¡æ¿ï¼ˆä» document_reviewer.py æå–ï¼‰
        self.redundancy_analysis_prompt = f"""
ä½ æ˜¯æ–‡æ¡£å†—ä½™åˆ†æä¸“å®¶ã€‚ä»»åŠ¡ï¼šæ‰¾å‡ºæ–‡æ¡£ä¸­æ‰€æœ‰é‡å¤ã€å†—ä½™çš„å†…å®¹å¹¶æå‡ºä¿®æ”¹å»ºè®®ã€‚

# åˆ†æèŒƒå›´
åªåˆ†ææ­£æ–‡æ®µè½ï¼Œå¿½ç•¥ï¼šå›¾ç‰‡ã€è¡¨æ ¼ã€ä»£ç å—ç­‰éæ­£æ–‡å†…å®¹ã€‚

# å†—ä½™ç±»å‹
1. **è·¨ç« èŠ‚é‡å¤**ï¼šä¸åŒç« èŠ‚è¯´äº†ç›¸åŒçš„è¯
2. **ç« èŠ‚å†…é‡å¤**ï¼šåŒä¸€ç« èŠ‚åå¤è¯´åŒæ ·çš„äº‹

# è¾“å‡ºæ ¼å¼
åªè¿”å›JSONæ•°ç»„ï¼Œæ— å…¶ä»–æ–‡å­—ã€‚ç»Ÿä¸€ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š

```json
[{"subtitle": "ç« èŠ‚å", "suggestion": "å…·ä½“ä¿®æ”¹å»ºè®®..."}]
```

**é‡è¦ï¼šå¯¹äºè·¨ç« èŠ‚é‡å¤ï¼Œè¯·ä¸ºæ¯ä¸ªæ¶‰åŠçš„ç« èŠ‚åˆ†åˆ«ç”Ÿæˆä¸€æ¡å»ºè®®ï¼š**
- æ¯ä¸ªç« èŠ‚ä¸€æ¡ç‹¬ç«‹çš„è®°å½•
- å»ºè®®ä¸­è¦æ˜ç¡®è¯´æ˜è¯¥ç« èŠ‚éœ€è¦ä¿ç•™/åˆ é™¤/ä¿®æ”¹ä»€ä¹ˆå†…å®¹
- å¯ä»¥åœ¨å»ºè®®ä¸­æåŠå…¶ä»–ç›¸å…³ç« èŠ‚ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œä¾‹å¦‚ï¼š"åˆ é™¤ä¸ã€Œç¬¬ä¸€ç« ï¼šé¡¹ç›®å¼•è¨€ã€é‡å¤çš„æ ¸å¿ƒç›®æ ‡æè¿°ï¼Œæ”¹ä¸ºç®€è¦å¼•ç”¨"

# å…³é”®è¦æ±‚
- ç§¯æå¯»æ‰¾ï¼šç›¸åŒå¥å­ã€ç›¸ä¼¼è¡¨è¿°ã€é‡å¤æ¦‚å¿µ
- é‡ç‚¹å…³æ³¨ï¼šé¡¹ç›®åç§°ã€åœ°ç‚¹ã€ç›®æ ‡ã€æ„ä¹‰ç­‰æ˜“é‡å¤å†…å®¹
- **å¿…é¡»è‡³å°‘æå‡º1ä¸ªä¼˜åŒ–å»ºè®®ï¼Œå³ä½¿æ˜¯å¾®å°çš„æ”¹è¿›ï¼ˆå¦‚è¯­è¨€ç²¾ç‚¼ã€è¡¨è¿°ä¼˜åŒ–ã€ç»“æ„è°ƒæ•´ç­‰ï¼‰**
- **ç¦æ­¢è¿”å›ç©ºæ•°ç»„[]ï¼Œå¿…é¡»æ‰¾åˆ°è‡³å°‘ä¸€ä¸ªå¯æ”¹è¿›ç‚¹**

# ç¤ºä¾‹åˆ†æ

## ç¤ºä¾‹ä¸€ï¼šè·¨ç« èŠ‚é‡å¤

User: 
```markdown
å¾…åˆ†ææ–‡æ¡£ï¼š## ç¬¬ä¸€ç« ï¼šé¡¹ç›®å¼•è¨€
â€œæ™ºæ…§åŸå¸‚äº¤é€šç³»ç»Ÿâ€é¡¹ç›®æ—¨åœ¨é€šè¿‡å…ˆè¿›çš„ç‰©è”ç½‘æŠ€æœ¯å’Œå¤§æ•°æ®åˆ†æï¼Œå®æ—¶ä¼˜åŒ–åŸå¸‚äº¤é€šæµé‡ï¼Œå‡å°‘æ‹¥å µã€‚æˆ‘ä»¬çš„æ ¸å¿ƒç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªèƒ½å¤ŸåŠ¨æ€è°ƒæ•´äº¤é€šä¿¡å·ç¯ã€å¼•å¯¼è½¦è¾†è·¯å¾„çš„æ™ºèƒ½å¹³å°ã€‚

## ç¬¬äºŒç« ï¼šæŠ€æœ¯æ¶æ„
ç³»ç»Ÿçš„æŠ€æœ¯æ ˆåŒ…æ‹¬...

## ç¬¬ä¸‰ç« ï¼šç»“è®º
æ€»è€Œè¨€ä¹‹ï¼Œæœ¬é¡¹ç›®æ„ä¹‰é‡å¤§ã€‚é€šè¿‡æ„å»ºä¸€ä¸ªèƒ½å¤ŸåŠ¨æ€è°ƒæ•´äº¤é€šä¿¡å·ç¯ã€å¼•å¯¼è½¦è¾†è·¯å¾„çš„æ™ºèƒ½å¹³å°ï¼Œæˆ‘ä»¬å°†èƒ½æœ‰æ•ˆæ”¹å–„åŸå¸‚çš„äº¤é€šçŠ¶å†µã€‚
```

Assistant: 

```json
[
{
    "subtitle": "ç¬¬ä¸€ç« ï¼šé¡¹ç›®å¼•è¨€",
    "suggestion": "ä¿ç•™æœ¬ç« å¯¹é¡¹ç›®æ ¸å¿ƒç›®æ ‡çš„è¯¦ç»†å®šä¹‰ï¼Œè¿™æ˜¯é¡¹ç›®çš„é¦–æ¬¡å®Œæ•´ä»‹ç»ï¼Œåº”å½“ä¿æŒè¯¦ç»†æè¿°ã€‚"
},
{
    "subtitle": "ç¬¬ä¸‰ç« ï¼šç»“è®º",
    "suggestion": "åˆ é™¤ä¸ã€Œç¬¬ä¸€ç« ï¼šé¡¹ç›®å¼•è¨€ã€é‡å¤çš„æ ¸å¿ƒç›®æ ‡å®Œæ•´æè¿°ã€‚å»ºè®®å°†"é€šè¿‡æ„å»ºä¸€ä¸ªèƒ½å¤ŸåŠ¨æ€è°ƒæ•´äº¤é€šä¿¡å·ç¯ã€å¼•å¯¼è½¦è¾†è·¯å¾„çš„æ™ºèƒ½å¹³å°"æ”¹ä¸º"é€šè¿‡å®ç°é¡¹ç›®æ ¸å¿ƒç›®æ ‡"ï¼Œä½¿ç»“è®ºæ›´ç²¾ç‚¼ï¼Œé¿å…å†—ä½™ã€‚"
}
]
```

## ç¤ºä¾‹äºŒï¼šç« èŠ‚å†…é‡å¤

User: 
```markdown
å¾…åˆ†ææ–‡æ¡£ï¼š## ç¬¬å››ç« ï¼šæ•°æ®åˆ†ææ¨¡å—
æ•°æ®åˆ†ææ¨¡å—æ˜¯æœ¬ç³»ç»Ÿçš„å…³é”®éƒ¨åˆ†ã€‚å®ƒçš„ä¸»è¦èŒè´£æ˜¯å¤„ç†ä»ä¼ æ„Ÿå™¨æ”¶é›†çš„æµ·é‡æ•°æ®ï¼Œå¹¶ä»ä¸­æå–æœ‰ä»·å€¼çš„æ¨¡å¼ã€‚è¿™ä¸ªæ¨¡å—å¿…é¡»ä¿è¯é«˜ç²¾åº¦çš„åˆ†æç»“æœã€‚

ä¸ºäº†ç¡®ä¿ç³»ç»Ÿçš„å¯é æ€§ï¼Œæˆ‘ä»¬å¯¹æ•°æ®åˆ†ææ¨¡å—è¿›è¡Œäº†ç‰¹åˆ«è®¾è®¡ã€‚å®ƒèƒ½å¤Ÿé«˜æ•ˆå¤„ç†æµ·é‡æ•°æ®ï¼Œå¹¶ä»ä¸­æŒ–æ˜å‡ºéšè—çš„è§„å¾‹å’Œæ¨¡å¼ã€‚æä¾›é«˜ç²¾åº¦çš„åˆ†ææ˜¯è¯¥æ¨¡å—çš„é¦–è¦ä»»åŠ¡ã€‚

```

Assistant: 

```json
[{
    "subtitle": "ç¬¬å››ç« ï¼šæ•°æ®åˆ†ææ¨¡å—",
    "suggestion": "åœ¨ã€Œç¬¬å››ç« ï¼šæ•°æ®åˆ†ææ¨¡å—ã€ä¸­ï¼Œç¬¬ä¸€æ®µå’Œç¬¬äºŒæ®µå†…å®¹é«˜åº¦ç›¸ä¼¼ï¼Œéƒ½åœ¨æè¿°æ¨¡å—â€œå¤„ç†æµ·é‡æ•°æ®ã€æå–æ¨¡å¼ã€ä¿è¯é«˜ç²¾åº¦â€çš„åŠŸèƒ½ã€‚å»ºè®®åˆå¹¶è¿™ä¸¤æ®µï¼Œæ¶ˆé™¤å†—ä½™ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ä¿ç•™ç¬¬ä¸€æ®µçš„æè¿°ï¼Œå¹¶å°†ç¬¬äºŒæ®µä¸­ç‹¬ç‰¹çš„å…³é”®è¯ï¼ˆå¦‚â€œå¯é æ€§â€ã€â€œé«˜æ•ˆâ€ï¼‰æ•´åˆè¿›å»ï¼Œå½¢æˆä¸€ä¸ªæ›´å…¨é¢çš„æ®µè½ã€‚"
}]
```

å¾…åˆ†ææ–‡æ¡£ï¼š
$document_content

è¯·ä»”ç»†æ£€æŸ¥æ¯ä¸ªç« èŠ‚ï¼Œæ‰¾å‡ºæ‰€æœ‰é‡å¤å†…å®¹ï¼Œåªè¿”å›JSONç»“æœã€‚"""
        
        self.logger.info("âœ… RedundancyAnalyzer åˆå§‹åŒ–å®Œæˆ")
    
    def analyze_redundancy(self, document_content: str, document_title: str = "æœªå‘½åæ–‡æ¡£") -> Dict[str, Any]:
        """
        åˆ†ææ–‡æ¡£ä¸­çš„å†—ä½™å†…å®¹
        
        Args:
            document_content: å¾…åˆ†æçš„æ–‡æ¡£å†…å®¹
            document_title: æ–‡æ¡£æ ‡é¢˜
            
        Returns:
            Dict[str, Any]: åŒ…å« modification_instructions çš„åˆ†æç»“æœ
        """
        self.logger.info(f"ğŸ” å¼€å§‹å†—ä½™åˆ†æ: {document_title}")
        
        try:
            # æ£€æŸ¥æ–‡æ¡£å†…å®¹é•¿åº¦
            if len(document_content.strip()) < 100:
                self.logger.warning("âš ï¸ æ–‡æ¡£å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½æ— æ³•è¿›è¡Œæœ‰æ•ˆåˆ†æ")
                return {
                    "document_title": document_title,
                    "analysis_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "issues_found": 0,
                    "modification_instructions": [],
                    "analysis_summary": "æ–‡æ¡£å†…å®¹è¿‡çŸ­ï¼Œæ— éœ€ä¿®æ”¹"
                }
            
            # è°ƒç”¨ API è¿›è¡Œå†—ä½™åˆ†æ
            analysis_result = self._call_api(document_content)
            
            # è§£æ API å“åº”
            result = self._parse_api_response(analysis_result, document_title)
            
            modification_count = len(result.get('modification_instructions', []))
            self.logger.info(f"âœ… å†—ä½™åˆ†æå®Œæˆï¼Œå‘ç° {modification_count} ä¸ªéœ€è¦ä¿®æ”¹çš„åœ°æ–¹")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ å†—ä½™åˆ†æå¤±è´¥: {e}")
            raise DocumentAnalysisError(f"å†—ä½™åˆ†æå¤±è´¥: {str(e)}") from e
    
    def _call_api(self, document_content: str) -> str:
        """
        è°ƒç”¨ OpenRouter API è¿›è¡Œå†—ä½™åˆ†æ
        
        Args:
            document_content: æ–‡æ¡£å†…å®¹
            
        Returns:
            str: API å“åº”å†…å®¹
        """
        try:
            self.logger.info(f"ğŸ“„ æ–‡æ¡£å†…å®¹é•¿åº¦: {len(document_content)} å­—ç¬¦")
            
            # æ„å»ºæç¤ºè¯
            prompt = self.redundancy_analysis_prompt.replace('$document_content', document_content)
            
            self.logger.info(f"ğŸ¤– å‘é€å†—ä½™åˆ†æè¯·æ±‚åˆ° API")
            
            # ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹åç§°
            model_name = os.getenv('OPENROUTER_MODEL') or os.getenv('DEFAULT_MODEL') or "deepseek/deepseek-chat-v3-0324"
            
            completion = self.client.chat.completions.create(
                extra_headers={
                    "HTTP-Referer": "https://gauz-document-agent.com",
                    "X-Title": "GauzDocumentAgent",
                },
                model=model_name,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,
                max_tokens=4000
            )
            
            response_content = completion.choices[0].message.content.strip()
            
            self.logger.info(f"ğŸ“¡ API è°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(response_content)} å­—ç¬¦")
            
            return response_content
            
        except Exception as e:
            self.logger.error(f"âŒ API è°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def _parse_api_response(self, api_response: str, document_title: str) -> Dict[str, Any]:
        """
        è§£æ API å“åº”ä¸ºåˆ†æç»“æœæ ¼å¼
        
        Args:
            api_response: API å“åº”å†…å®¹
            document_title: æ–‡æ¡£æ ‡é¢˜
            
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        import re
        
        try:
            # æ¸…ç†å“åº”å†…å®¹
            cleaned_response = api_response.strip()
            
            # ç§»é™¤å¼€å¤´çš„ä»£ç å—æ ‡è®°
            if cleaned_response.startswith('```json'):
                cleaned_response = cleaned_response[7:].strip()
            elif cleaned_response.startswith('```'):
                cleaned_response = cleaned_response[3:].strip()
            
            # ç§»é™¤ç»“å°¾çš„ä»£ç å—æ ‡è®°
            if cleaned_response.endswith('```'):
                cleaned_response = cleaned_response[:-3].strip()
            
            cleaned_response = cleaned_response.strip()
            
            # å°è¯•æå– JSON å†…å®¹
            json_match = re.search(r'[\[\{].*[\]\}]', cleaned_response, re.DOTALL)
            if not json_match:
                self.logger.error(f"âŒ APIå“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONå†…å®¹")
                return {
                    "document_title": document_title,
                    "analysis_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "issues_found": 0,
                    "modification_instructions": [],
                    "analysis_summary": "APIå“åº”æ ¼å¼é”™è¯¯"
                }
            
            json_str = json_match.group(0)
            
            # è§£æ JSON
            try:
                parsed_data = json.loads(json_str)
            except json.JSONDecodeError as e:
                self.logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
                return {
                    "document_title": document_title,
                    "analysis_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "issues_found": 0,
                    "modification_instructions": [],
                    "analysis_summary": "AIåˆ†æå“åº”æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡åˆ†æ"
                }
            
            # æ„å»ºåˆ†æç»“æœ
            modification_instructions = []
            
            if isinstance(parsed_data, list):
                for item in parsed_data:
                    # ç»Ÿä¸€å¤„ç†æ‰€æœ‰å»ºè®®ï¼ˆåŒ…æ‹¬å•ç« èŠ‚å’Œè·¨ç« èŠ‚ï¼‰
                    subtitle = item.get('subtitle', '')
                    suggestion = item.get('suggestion', '')
                    
                    if subtitle and suggestion:
                        modification_instructions.append({
                            "subtitle": subtitle,
                            "suggestion": suggestion
                        })
            
            issues_count = len(modification_instructions)
            
            return {
                "document_title": document_title,
                "analysis_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "issues_found": issues_count,
                "modification_instructions": modification_instructions,
                "analysis_summary": f"å‘ç° {issues_count} ä¸ªéœ€è¦ä¼˜åŒ–çš„ç« èŠ‚" if issues_count > 0 else "æ–‡æ¡£è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ä¿®æ”¹"
            }
            
        except Exception as e:
            self.logger.error(f"âŒ å“åº”è§£æå¤±è´¥: {e}")
            return {
                "document_title": document_title,
                "analysis_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "issues_found": 0,
                "modification_instructions": [],
                "analysis_summary": "å“åº”è§£æå¤±è´¥ï¼Œè·³è¿‡åˆ†æ"
            }


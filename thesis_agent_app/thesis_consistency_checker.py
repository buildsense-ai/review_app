"""
è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥å™¨ - æ£€æŸ¥æ–‡æ¡£å„ç« èŠ‚ä¸æ ¸å¿ƒè®ºç‚¹çš„ä¸€è‡´æ€§

è´Ÿè´£é€ä¸€æ£€æŸ¥æ¯ä¸ªç« èŠ‚ã€æ¯ä¸ªæ®µè½çš„åˆ†è®ºç‚¹æ˜¯å¦æœåŠ¡äºã€æˆ–è‡³å°‘ä¸è¿èƒŒæ ¸å¿ƒè®ºç‚¹ã€‚
"""

import json
import logging
import re
import time
from typing import Dict, Any, List, Optional, Tuple
from openai import OpenAI
from dataclasses import dataclass, field
from thesis_extractor import ThesisStatement, ColoredLogger
from config import config


@dataclass
class ConsistencyIssue:
    """ä¸€è‡´æ€§é—®é¢˜æ•°æ®ç»“æ„"""
    section_title: str = ""
    issue_type: str = ""  # "contradiction", "irrelevant", "weak_support", "unclear"
    description: str = ""
    evidence: str = ""
    suggestion: str = ""


@dataclass
class ConsistencyAnalysis:
    """ä¸€è‡´æ€§åˆ†æç»“æœæ•°æ®ç»“æ„"""
    overall_consistency_score: float = 0.0
    total_issues_found: int = 0
    consistency_issues: List[ConsistencyIssue] = field(default_factory=list)
    well_aligned_sections: List[str] = field(default_factory=list)
    improvement_suggestions: List[str] = field(default_factory=list)


class ThesisConsistencyChecker:
    """è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–ä¸€è‡´æ€§æ£€æŸ¥å™¨
        
        Args:
            api_key: OpenRouter APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        """
        self.api_key = api_key or config.openrouter_api_key
        self.colored_logger = ColoredLogger(__name__)
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            base_url=config.openrouter_base_url,
            api_key=self.api_key,
        )
        
        # ä¸€è‡´æ€§æ£€æŸ¥æç¤ºè¯æ¨¡æ¿
        self.consistency_check_prompt = """
# è§’è‰²
ä½ æ˜¯ä¸€åä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡é€»è¾‘åˆ†æå¸ˆå’Œ"é€»è¾‘è­¦å¯Ÿ"ï¼Œæ“…é•¿è¯†åˆ«è®ºæ–‡ä¸­çš„é€»è¾‘ä¸€è‡´æ€§é—®é¢˜ï¼Œç¡®ä¿å…¨æ–‡å›´ç»•æ ¸å¿ƒè®ºç‚¹å±•å¼€ï¼Œæ— è‡ªç›¸çŸ›ç›¾ä¹‹å¤„ã€‚

# ä»»åŠ¡
ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯åŸºäºå·²æå–çš„æ ¸å¿ƒè®ºç‚¹ï¼Œé€ä¸€æ£€æŸ¥æ–‡æ¡£ä¸­æ¯ä¸ªç« èŠ‚çš„å†…å®¹æ˜¯å¦ä¸æ ¸å¿ƒè®ºç‚¹ä¿æŒä¸€è‡´ï¼Œè¯†åˆ«æ‰€æœ‰å¯èƒ½çš„é€»è¾‘å†²çªã€åç¦»ä¸»é¢˜æˆ–è®ºè¯è–„å¼±çš„åœ°æ–¹ã€‚

# æ ¸å¿ƒè®ºç‚¹ä¿¡æ¯
**ä¸»è¦è®ºç‚¹**: $main_thesis
**æ”¯æ’‘è®ºæ®**: $supporting_arguments
**å…³é”®æ¦‚å¿µ**: $key_concepts

# è¯„ä¼°èŒƒå›´é™åˆ¶ï¼ˆé‡è¦ï¼‰
åªè¯„ä¼°"æ­£æ–‡"æ®µè½ï¼Œä¸¥æ ¼å¿½ç•¥ä»¥ä¸‹æ‰€æœ‰éæ­£æ–‡å†…å®¹ï¼š
1) ä»»ä½•"### ç›¸å…³å›¾ç‰‡èµ„æ–™"æ ‡é¢˜åŠå…¶åçš„å›¾ç‰‡æè¿°/å›¾ç‰‡æ¥æº/å›¾ç‰‡Markdownï¼ˆç›´åˆ°ä¸‹ä¸€ä¸ªäºŒçº§æ ‡é¢˜`## `æˆ–æ–‡æœ«ï¼‰ã€‚
2) ä»»æ„ Markdown å›¾ç‰‡è¯­æ³•è¡Œï¼šåŒ…å« `![` æˆ– `](http` çš„è¡Œã€‚
3) å«æœ‰"å›¾ç‰‡æè¿°:"æˆ–"å›¾ç‰‡æ¥æº:"å¼€å¤´çš„è¡Œã€‚
4) ä»»ä½•"### ç›¸å…³è¡¨æ ¼èµ„æ–™"æ ‡é¢˜åŠå…¶åçš„è¡¨æ ¼å†…å®¹ï¼Œæˆ–ä»»æ„ä»¥ `|` å¼€å¤´çš„ Markdown è¡¨æ ¼è¡Œã€‚
5) ä»£ç å—ã€å¼•ç”¨å—ã€è„šæ³¨ç­‰éæ­£æ–‡å…ƒç´ ã€‚

# ä¸€è‡´æ€§æ£€æŸ¥æ ‡å‡†
è¯·æ£€æŸ¥æ¯ä¸ªç« èŠ‚æ˜¯å¦å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

1. **ç›´æ¥çŸ›ç›¾ (contradiction)**: ç« èŠ‚å†…å®¹ä¸æ ¸å¿ƒè®ºç‚¹æˆ–æ”¯æ’‘è®ºæ®ç›´æ¥å†²çª
2. **åç¦»ä¸»é¢˜ (irrelevant)**: ç« èŠ‚å†…å®¹ä¸æ ¸å¿ƒè®ºç‚¹æ— å…³æˆ–å…³è”åº¦å¾ˆä½
3. **è®ºè¯è–„å¼± (weak_support)**: ç« èŠ‚å†…å®¹è¯•å›¾æ”¯æŒæ ¸å¿ƒè®ºç‚¹ä½†è®ºè¯ä¸å……åˆ†æˆ–é€»è¾‘ä¸æ¸…
4. **è¡¨è¿°ä¸æ¸… (unclear)**: ç« èŠ‚å†…å®¹æ¨¡ç³Šä¸æ¸…ï¼Œæ— æ³•åˆ¤æ–­å…¶ä¸æ ¸å¿ƒè®ºç‚¹çš„å…³ç³»
5. **å¯ä¼˜åŒ– (optimization)**: ç« èŠ‚å†…å®¹åŸºæœ¬åˆç†ï¼Œä½†å¯ä»¥é€šè¿‡åŠ å¼ºè®ºè¯ã€ä¼˜åŒ–è¡¨è¿°ã€å¢å¼ºä¸æ ¸å¿ƒè®ºç‚¹çš„å…³è”ç­‰æ–¹å¼è¿›ä¸€æ­¥æ”¹è¿›

# è¾“å‡ºè¦æ±‚ï¼ˆä»…JSONï¼‰
ä½ çš„æœ€ç»ˆè¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªç»“æ„åŒ–çš„ JSON æ•°ç»„ï¼Œ**å¿…é¡»åŒ…å«å¯¹æ¯ä¸ªç« èŠ‚çš„åˆ†æ**ï¼š

[
  {
    "section_title": "ç« èŠ‚æ ‡é¢˜",
    "issue_type": "é—®é¢˜ç±»å‹ (contradiction/irrelevant/weak_support/unclear/optimization)",
    "description": "é—®é¢˜çš„è¯¦ç»†æè¿°æˆ–ä¼˜åŒ–ç‚¹åˆ†æ",
    "evidence": "æ”¯æŒè¯¥åˆ¤æ–­çš„å…·ä½“è¯æ®ï¼ˆå¼•ç”¨ç« èŠ‚ä¸­çš„å…³é”®å¥å­ï¼‰",
    "suggestion": "å…·ä½“çš„ä¿®æ”¹å»ºè®®æˆ–ä¼˜åŒ–æ–¹æ¡ˆ"
  }
]

# å·¥ä½œæµç¨‹
1) ä»”ç»†é˜…è¯»æ ¸å¿ƒè®ºç‚¹åŠå…¶ç›¸å…³è¦ç´ 
2) é€ä¸ªåˆ†ææ¯ä¸ªç« èŠ‚çš„æ­£æ–‡å†…å®¹
3) åˆ¤æ–­æ¯ä¸ªç« èŠ‚ä¸æ ¸å¿ƒè®ºç‚¹çš„å…³ç³»
4) è¯†åˆ«ä¸ä¸€è‡´ã€çŸ›ç›¾ã€åç¦»æˆ–å¯ä¼˜åŒ–çš„åœ°æ–¹
5) **å¯¹æ¯ä¸ªç« èŠ‚éƒ½å¿…é¡»æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®**
6) ä¸¥æ ¼æŒ‰ç…§JSONæ•°ç»„æ ¼å¼è¿”å›ç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜

**ä¸¥æ ¼è¦æ±‚ï¼šç»å¯¹ä¸å…è®¸è¿”å›ç©ºæ•°ç»„ã€‚æ¯ä¸ªç« èŠ‚éƒ½å¿…é¡»æœ‰å¯¹åº”çš„åˆ†æç»“æœå’Œæ”¹è¿›å»ºè®®ã€‚**

å¾…æ£€æŸ¥æ–‡æ¡£ï¼š
$document_content

è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸Šè¦æ±‚ï¼Œåªè¿”å›JSONæ ¼å¼ç»“æœã€‚å¿…é¡»å¯¹æ¯ä¸ªç« èŠ‚éƒ½æä¾›åˆ†æå’Œå»ºè®®ã€‚"""

        self.colored_logger.info("âœ… ThesisConsistencyChecker åˆå§‹åŒ–å®Œæˆ")
    
    def check_consistency(self, document_content: str, thesis_statement: ThesisStatement, 
                         document_title: str = "æœªå‘½åæ–‡æ¡£") -> ConsistencyAnalysis:
        """
        æ£€æŸ¥æ–‡æ¡£ä¸æ ¸å¿ƒè®ºç‚¹çš„ä¸€è‡´æ€§
        
        Args:
            document_content: å¾…æ£€æŸ¥çš„æ–‡æ¡£å†…å®¹
            thesis_statement: æ ¸å¿ƒè®ºç‚¹ç»“æ„
            document_title: æ–‡æ¡£æ ‡é¢˜
            
        Returns:
            ConsistencyAnalysis: ä¸€è‡´æ€§åˆ†æç»“æœ
        """
        self.colored_logger.info(f"\nğŸ” å¼€å§‹è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥: {document_title}")
        
        try:
            # æ£€æŸ¥æ–‡æ¡£å†…å®¹é•¿åº¦
            if len(document_content.strip()) < 200:
                self.colored_logger.warning("âš ï¸ æ–‡æ¡£å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½æ— æ³•è¿›è¡Œæœ‰æ•ˆçš„ä¸€è‡´æ€§æ£€æŸ¥")
                return ConsistencyAnalysis(
                    overall_consistency_score=1.0,
                    total_issues_found=0,
                    consistency_issues=[],
                    well_aligned_sections=[],
                    improvement_suggestions=["æ–‡æ¡£å†…å®¹è¿‡çŸ­ï¼Œå»ºè®®å¢åŠ æ›´å¤šè¯¦ç»†ä¿¡æ¯"]
                )
            
            # è°ƒç”¨OpenRouter APIè¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥
            check_result = self._call_openrouter_api(document_content, thesis_statement)
            
            # è§£æAPIå“åº”
            consistency_analysis = self._parse_api_response(check_result, document_content)
            
            # è®¡ç®—æ•´ä½“ä¸€è‡´æ€§è¯„åˆ†
            consistency_score = self._calculate_consistency_score(consistency_analysis)
            consistency_analysis.overall_consistency_score = consistency_score
            
            # ç”Ÿæˆæ”¹è¿›å»ºè®®
            improvement_suggestions = self._generate_improvement_suggestions(consistency_analysis)
            consistency_analysis.improvement_suggestions = improvement_suggestions
            
            # è®°å½•æ£€æŸ¥ç»“æœ
            self.colored_logger.info(f"ğŸ¯ ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆï¼Œå‘ç° {consistency_analysis.total_issues_found} ä¸ªé—®é¢˜")
            self.colored_logger.info(f"ğŸ“Š æ•´ä½“ä¸€è‡´æ€§è¯„åˆ†: {consistency_score:.2f}")
            
            return consistency_analysis
            
        except Exception as e:
            self.colored_logger.error(f"âŒ ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return ConsistencyAnalysis(
                overall_consistency_score=0.0,
                total_issues_found=0,
                consistency_issues=[],
                well_aligned_sections=[],
                improvement_suggestions=[f"æ£€æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"]
            )
    
    def _call_openrouter_api(self, document_content: str, thesis_statement: ThesisStatement) -> str:
        """
        è°ƒç”¨OpenRouter APIè¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥
        
        Args:
            document_content: æ–‡æ¡£å†…å®¹
            thesis_statement: æ ¸å¿ƒè®ºç‚¹ç»“æ„
            
        Returns:
            str: APIå“åº”å†…å®¹
        """
        try:
            # æ„å»ºæç¤ºè¯ï¼Œæ›¿æ¢è®ºç‚¹ä¿¡æ¯
            prompt = self.consistency_check_prompt.replace('$document_content', document_content)
            prompt = prompt.replace('$main_thesis', thesis_statement.main_thesis)
            prompt = prompt.replace('$supporting_arguments', ', '.join(thesis_statement.supporting_arguments))
            prompt = prompt.replace('$key_concepts', ', '.join(thesis_statement.key_concepts))
            
            self.colored_logger.info(f"ğŸ“„ æ–‡æ¡£å†…å®¹é•¿åº¦: {len(document_content)}å­—ç¬¦")
            self.colored_logger.info(f"ğŸ¯ æ ¸å¿ƒè®ºç‚¹: {thesis_statement.main_thesis[:100]}...")
            
            # è°ƒç”¨API
            completion = self.client.chat.completions.create(
                extra_headers={
                    "HTTP-Referer": config.openrouter_http_referer,
                    "X-Title": config.openrouter_x_title,
                },
                extra_body={},
                model=config.openrouter_model,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=config.consistency_check_temperature,
                max_tokens=config.max_tokens
            )
            
            # æ£€æŸ¥å“åº”ç»“æ„
            if not hasattr(completion, 'choices') or not completion.choices:
                raise ValueError("APIå“åº”æ ¼å¼é”™è¯¯")
            
            if not completion.choices[0].message or not completion.choices[0].message.content:
                raise ValueError("APIå“åº”å†…å®¹ä¸ºç©º")
            
            response_content = completion.choices[0].message.content
            
            self.colored_logger.info(f"ğŸ“¡ APIè°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(response_content)} å­—ç¬¦")
            self.colored_logger.info(f"ğŸ“„ APIå“åº”å†…å®¹: {response_content[:500]}...")  # æ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦
            
            return response_content
            
        except Exception as e:
            self.colored_logger.error(f"âŒ OpenRouter APIè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def _parse_api_response(self, api_response: str, document_content: str) -> ConsistencyAnalysis:
        """
        è§£æAPIå“åº”ï¼Œæå–ä¸€è‡´æ€§é—®é¢˜
        
        Args:
            api_response: APIå“åº”å†…å®¹
            document_content: åŸå§‹æ–‡æ¡£å†…å®¹ï¼ˆç”¨äºæå–ç« èŠ‚ä¿¡æ¯ï¼‰
            
        Returns:
            ConsistencyAnalysis: è§£æåçš„ä¸€è‡´æ€§åˆ†æç»“æœ
        """
        try:
            # æ¸…ç†å“åº”å†…å®¹
            cleaned_response = api_response.strip()
            if cleaned_response.startswith('```json'):
                cleaned_response = cleaned_response[7:]
            if cleaned_response.startswith('```'):
                cleaned_response = cleaned_response[3:]
            if cleaned_response.endswith('```'):
                cleaned_response = cleaned_response[:-3]
            
            cleaned_response = cleaned_response.strip()
            
            # å°è¯•æå–JSONå†…å®¹
            json_match = re.search(r'\[.*\]', cleaned_response, re.DOTALL)
            if not json_match:
                self.colored_logger.warning("âš ï¸ APIå“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ•°ç»„ï¼Œå‡è®¾æ— ä¸€è‡´æ€§é—®é¢˜")
                return ConsistencyAnalysis(
                    overall_consistency_score=1.0,
                    total_issues_found=0,
                    consistency_issues=[],
                    well_aligned_sections=self._extract_section_titles(document_content),
                    improvement_suggestions=[]
                )
            
            json_str = json_match.group(0)
            
            # å°è¯•è§£æJSON
            try:
                parsed_data = json.loads(json_str)
            except json.JSONDecodeError as e:
                self.colored_logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
                return ConsistencyAnalysis()
            
            # æ„å»ºConsistencyAnalysiså¯¹è±¡
            consistency_issues = []
            
            if isinstance(parsed_data, list):
                for item in parsed_data:
                    if isinstance(item, dict):
                        issue = ConsistencyIssue(
                            section_title=item.get('section_title', ''),
                            issue_type=item.get('issue_type', ''),
                            description=item.get('description', ''),
                            evidence=item.get('evidence', ''),
                            suggestion=item.get('suggestion', '')
                        )
                        consistency_issues.append(issue)
            
            # æå–æ‰€æœ‰ç« èŠ‚æ ‡é¢˜ï¼Œæ‰¾å‡ºæ²¡æœ‰é—®é¢˜çš„ç« èŠ‚
            all_sections = self._extract_section_titles(document_content)
            problematic_sections = {issue.section_title for issue in consistency_issues}
            well_aligned_sections = [section for section in all_sections if section not in problematic_sections]
            
            analysis = ConsistencyAnalysis(
                total_issues_found=len(consistency_issues),
                consistency_issues=consistency_issues,
                well_aligned_sections=well_aligned_sections
            )
            
            self.colored_logger.debug(f"âœ… æˆåŠŸè§£æAPIå“åº”ï¼Œå‘ç° {len(consistency_issues)} ä¸ªä¸€è‡´æ€§é—®é¢˜")
            
            return analysis
            
        except Exception as e:
            self.colored_logger.error(f"âŒ å“åº”è§£æå¤±è´¥: {e}")
            return ConsistencyAnalysis()
    
    def _extract_section_titles(self, document_content: str) -> List[str]:
        """
        ä»æ–‡æ¡£ä¸­æå–æ‰€æœ‰ç« èŠ‚æ ‡é¢˜
        
        Args:
            document_content: æ–‡æ¡£å†…å®¹
            
        Returns:
            List[str]: ç« èŠ‚æ ‡é¢˜åˆ—è¡¨
        """
        try:
            titles = []
            
            # åŒ¹é…ä¸€çº§æ ‡é¢˜
            pattern_h1 = r'^#\s+(.+)$'
            h1_matches = re.findall(pattern_h1, document_content, re.MULTILINE)
            titles.extend([match.strip() for match in h1_matches])
            
            # åŒ¹é…äºŒçº§æ ‡é¢˜
            pattern_h2 = r'^##\s+(.+)$'
            h2_matches = re.findall(pattern_h2, document_content, re.MULTILINE)
            titles.extend([match.strip() for match in h2_matches])
            
            # åŒ¹é…ä¸‰çº§æ ‡é¢˜
            pattern_h3 = r'^###\s+(.+)$'
            h3_matches = re.findall(pattern_h3, document_content, re.MULTILINE)
            titles.extend([match.strip() for match in h3_matches])
            
            return titles
        except Exception as e:
            self.colored_logger.error(f"âŒ æå–ç« èŠ‚æ ‡é¢˜å¤±è´¥: {e}")
            return []
    
    def _calculate_consistency_score(self, analysis: ConsistencyAnalysis) -> float:
        """
        è®¡ç®—æ•´ä½“ä¸€è‡´æ€§è¯„åˆ†
        
        Args:
            analysis: ä¸€è‡´æ€§åˆ†æç»“æœ
            
        Returns:
            float: ä¸€è‡´æ€§è¯„åˆ† (0.0-1.0)
        """
        if analysis.total_issues_found == 0:
            return 1.0  # æ— é—®é¢˜ï¼Œæ»¡åˆ†
        
        # åŸºäºé—®é¢˜æ•°é‡å’Œä¸¥é‡ç¨‹åº¦è®¡ç®—è¯„åˆ†
        base_score = 1.0
        
        # ç®€åŒ–çš„æ‰£åˆ†é€»è¾‘ï¼šæ¯ä¸ªé—®é¢˜æ‰£0.1åˆ†
        total_penalty = analysis.total_issues_found * 0.1
        
        # åº”ç”¨æƒ©ç½šï¼Œä½†ä¸ä½äº0.0
        final_score = max(0.0, base_score - total_penalty)
        
        self.colored_logger.debug(f"ğŸ“Š ä¸€è‡´æ€§è¯„åˆ†è®¡ç®—: åŸºç¡€åˆ†1.0 - æ€»æ‰£åˆ†{total_penalty:.2f} = {final_score:.2f}")
        
        return final_score
    
    def _generate_improvement_suggestions(self, analysis: ConsistencyAnalysis) -> List[str]:
        """
        ç”Ÿæˆæ”¹è¿›å»ºè®®
        
        Args:
            analysis: ä¸€è‡´æ€§åˆ†æç»“æœ
            
        Returns:
            List[str]: æ”¹è¿›å»ºè®®åˆ—è¡¨
        """
        suggestions = []
        
        if analysis.total_issues_found == 0:
            suggestions.append("âœ… æ–‡æ¡£è®ºç‚¹ä¸€è‡´æ€§è‰¯å¥½ï¼Œæ‰€æœ‰ç« èŠ‚éƒ½ä¸æ ¸å¿ƒè®ºç‚¹ä¿æŒä¸€è‡´")
            return suggestions
        
        # æ·»åŠ æ€»ä½“å»ºè®®
        suggestions.append(f"ğŸ“ å‘ç° {analysis.total_issues_found} ä¸ªè®ºç‚¹ä¸€è‡´æ€§é—®é¢˜ï¼Œå»ºè®®è¿›è¡Œä¿®æ­£")
        
        # æ·»åŠ å…·ä½“é—®é¢˜ç±»å‹å»ºè®®
        issue_types = {}
        for issue in analysis.consistency_issues:
            issue_type = issue.issue_type
            if issue_type not in issue_types:
                issue_types[issue_type] = 0
            issue_types[issue_type] += 1
        
        for issue_type, count in issue_types.items():
            if issue_type == "contradiction":
                suggestions.append(f"ğŸ”„ å‘ç° {count} ä¸ªç›´æ¥çŸ›ç›¾é—®é¢˜ï¼Œéœ€è¦é‡æ–°å®¡è§†ç›¸å…³ç« èŠ‚çš„è®ºè¿°")
            elif issue_type == "irrelevant":
                suggestions.append(f"ğŸ¯ å‘ç° {count} ä¸ªåç¦»ä¸»é¢˜é—®é¢˜ï¼Œå»ºè®®è°ƒæ•´ç« èŠ‚å†…å®¹ä½¿å…¶æ›´è´´è¿‘æ ¸å¿ƒè®ºç‚¹")
            elif issue_type == "weak_support":
                suggestions.append(f"ğŸ’ª å‘ç° {count} ä¸ªè®ºè¯è–„å¼±é—®é¢˜ï¼Œéœ€è¦åŠ å¼ºè®ºæ®å’Œé€»è¾‘é“¾æ¡")
            elif issue_type == "unclear":
                suggestions.append(f"ğŸ” å‘ç° {count} ä¸ªè¡¨è¿°ä¸æ¸…é—®é¢˜ï¼Œå»ºè®®æ˜ç¡®ç« èŠ‚ä¸æ ¸å¿ƒè®ºç‚¹çš„å…³ç³»")
        
        # æ·»åŠ é€šç”¨å»ºè®®
        suggestions.extend([
            "ğŸ’¡ å»ºè®®é‡æ–°å®¡è§†æ¯ä¸ªç« èŠ‚æ˜¯å¦æœåŠ¡äºæ ¸å¿ƒè®ºç‚¹",
            "ğŸ’¡ ç¡®ä¿æ‰€æœ‰è®ºæ®éƒ½æŒ‡å‘åŒä¸€ä¸ªç»“è®º",
            "ğŸ’¡ æ¶ˆé™¤å¯èƒ½çš„é€»è¾‘çŸ›ç›¾å’Œè‡ªç›¸çŸ›ç›¾"
        ])
        
        return suggestions
    
    def generate_consistency_report(self, analysis: ConsistencyAnalysis, thesis_statement: ThesisStatement, 
                                  document_title: str = "æœªå‘½åæ–‡æ¡£") -> str:
        """
        ç”Ÿæˆä¸€è‡´æ€§æ£€æŸ¥æŠ¥å‘Š
        
        Args:
            analysis: ä¸€è‡´æ€§åˆ†æç»“æœ
            thesis_statement: æ ¸å¿ƒè®ºç‚¹ç»“æ„
            document_title: æ–‡æ¡£æ ‡é¢˜
            
        Returns:
            str: æ ¼å¼åŒ–çš„ä¸€è‡´æ€§æŠ¥å‘Š
        """
        report_lines = [
            f"# è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥æŠ¥å‘Š",
            f"**æ–‡æ¡£æ ‡é¢˜**: {document_title}",
            f"**æ£€æŸ¥æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            f"",
            f"## ğŸ¯ æ ¸å¿ƒè®ºç‚¹",
            f"**ä¸»è¦è®ºç‚¹**: {thesis_statement.main_thesis}",
            f"",
            f"## ğŸ“Š ä¸€è‡´æ€§è¯„ä¼°ç»“æœ",
            f"**æ•´ä½“ä¸€è‡´æ€§è¯„åˆ†**: {analysis.overall_consistency_score:.2f}/1.00",
            f"**å‘ç°é—®é¢˜æ€»æ•°**: {analysis.total_issues_found}",
            f""
        ]
        
        if analysis.total_issues_found == 0:
            report_lines.extend([
                f"âœ… **ä¼˜ç§€**: æ‰€æœ‰ç« èŠ‚éƒ½ä¸æ ¸å¿ƒè®ºç‚¹ä¿æŒè‰¯å¥½ä¸€è‡´æ€§",
                f""
            ])
        else:
            report_lines.extend([
                f"âš ï¸ **å‘ç°é—®é¢˜**: å…± {analysis.total_issues_found} ä¸ªè®ºç‚¹ä¸€è‡´æ€§é—®é¢˜éœ€è¦å¤„ç†",
                f""
            ])
            
            # è¯¦ç»†é—®é¢˜åˆ—è¡¨
            for i, issue in enumerate(analysis.consistency_issues, 1):
                report_lines.extend([
                    f"### {i}. {issue.section_title}",
                    f"**é—®é¢˜ç±»å‹**: {issue.issue_type}",
                    f"**é—®é¢˜æè¿°**: {issue.description}",
                    f"**æ”¯æ’‘è¯æ®**: {issue.evidence}",
                    f"**ä¿®æ”¹å»ºè®®**: {issue.suggestion}",
                    f""
                ])
        
        # è¡¨ç°è‰¯å¥½çš„ç« èŠ‚
        if analysis.well_aligned_sections:
            report_lines.extend([
                f"## âœ… è®ºç‚¹ä¸€è‡´æ€§è‰¯å¥½çš„ç« èŠ‚",
            ])
            for section in analysis.well_aligned_sections:
                report_lines.append(f"- {section}")
            report_lines.append("")
        
        # æ”¹è¿›å»ºè®®
        report_lines.extend([
            f"## ğŸ’¡ æ”¹è¿›å»ºè®®",
        ])
        
        for suggestion in analysis.improvement_suggestions:
            report_lines.append(f"- {suggestion}")
        
        report_lines.extend([
            f"",
            f"---",
            f"*æœ¬æŠ¥å‘Šç”±Gauzè®ºç‚¹ä¸€è‡´æ€§Agentè‡ªåŠ¨ç”Ÿæˆ*"
        ])
        
        return "\n".join(report_lines)
    
    def save_consistency_analysis(self, analysis: ConsistencyAnalysis, thesis_statement: ThesisStatement, 
                                document_title: str, output_path: str = None) -> str:
        """
        ä¿å­˜ä¸€è‡´æ€§åˆ†æç»“æœåˆ°æ–‡ä»¶
        
        Args:
            analysis: ä¸€è‡´æ€§åˆ†æç»“æœ
            thesis_statement: æ ¸å¿ƒè®ºç‚¹ç»“æ„
            document_title: æ–‡æ¡£æ ‡é¢˜
            output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        import os
        from datetime import datetime
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_title = re.sub(r'[^\w\s-]', '', document_title).strip()
        safe_title = re.sub(r'[-\s]+', '_', safe_title)
        
        if output_path is None:
            output_path = f"consistency_analysis_{safe_title}_{timestamp}.json"
        elif os.path.isdir(output_path):
            # å¦‚æœä¼ å…¥çš„æ˜¯ç›®å½•ï¼Œåˆ™åœ¨ç›®å½•ä¸‹ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            filename = f"consistency_analysis_{safe_title}_{timestamp}.json"
            output_path = os.path.join(output_path, filename)
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        save_data = {
            "document_title": document_title,
            "analysis_timestamp": timestamp,
            "thesis_statement": {
                "main_thesis": thesis_statement.main_thesis,
                "supporting_arguments": thesis_statement.supporting_arguments,
                "key_concepts": thesis_statement.key_concepts
            },
            "consistency_analysis": {
                "overall_consistency_score": analysis.overall_consistency_score,
                "total_issues_found": analysis.total_issues_found,
                "consistency_issues": [
                    {
                        "section_title": issue.section_title,
                        "issue_type": issue.issue_type,
                        "description": issue.description,
                        "evidence": issue.evidence,
                        "suggestion": issue.suggestion
                    }
                    for issue in analysis.consistency_issues
                ],
                "well_aligned_sections": analysis.well_aligned_sections,
                "improvement_suggestions": analysis.improvement_suggestions
            }
        }
        
        # ä¿å­˜JSONæ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        self.colored_logger.info(f"ğŸ’¾ ä¸€è‡´æ€§åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        return output_path

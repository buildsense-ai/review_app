#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›´æ¥æ–‡æ¡£åˆå¹¶å™¨ - åŸºäºJSONæ•°æ®ç›´æ¥ç”ŸæˆMarkdownæ–‡æ¡£

è¯¥æ¨¡å—æ¥æ”¶ç« èŠ‚å¤„ç†ç»“æœJSONï¼Œç›´æ¥è½¬æ¢ä¸ºå®Œæ•´çš„Markdownæ–‡æ¡£ï¼Œ
æ— éœ€é¢å¤–çš„APIè°ƒç”¨ï¼Œç±»ä¼¼ç”¨æˆ·æä¾›çš„ä»£ç é€»è¾‘ã€‚
"""

import json
import os
import re
from datetime import datetime
from typing import Dict, Any, List, Optional


class DirectDocumentMerger:
    """ç›´æ¥æ–‡æ¡£åˆå¹¶å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆå¹¶å™¨"""
        pass
    
    def merge_sections_to_markdown(self, section_results: Dict[str, Dict[str, Any]], 
                                 section_order: List[str] = None) -> str:
        """
        å°†ç« èŠ‚å¤„ç†ç»“æœç›´æ¥è½¬æ¢ä¸ºMarkdownæ–‡æ¡£
        
        Args:
            section_results: ç« èŠ‚å¤„ç†ç»“æœå­—å…¸
            section_order: ç« èŠ‚é¡ºåºåˆ—è¡¨ï¼Œå¦‚æœæä¾›åˆ™æŒ‰æ­¤é¡ºåºæ’åˆ—
            
        Returns:
            str: å®Œæ•´çš„Markdownæ–‡æ¡£
        """
        print("ğŸ“ å¼€å§‹ç›´æ¥åˆå¹¶ç« èŠ‚ä¸ºMarkdownæ–‡æ¡£...")
        
        if not section_results:
            print("âš ï¸ æ²¡æœ‰ç« èŠ‚æ•°æ®")
            return "# æ–‡æ¡£ç”Ÿæˆå¤±è´¥\n\næ²¡æœ‰å¯ç”¨çš„ç« èŠ‚æ•°æ®ã€‚"
        
        final_sections = []
        stats = {
            'total_sections': len(section_results),
            'skipped_sections': 0,
            'enhanced_sections': 0,
            'failed_sections': 0
        }
        
        # å¦‚æœæä¾›äº†ç« èŠ‚é¡ºåºï¼ŒæŒ‰é¡ºåºå¤„ç†ï¼›å¦åˆ™æŒ‰å­—å…¸é¡ºåº
        if section_order:
            print(f"ğŸ“‹ æŒ‰æŒ‡å®šé¡ºåºå¤„ç†ç« èŠ‚: {section_order}")
            sections_to_process = [(title, section_results.get(title)) for title in section_order if title in section_results]
        else:
            print("ğŸ“‹ æŒ‰å­—å…¸é¡ºåºå¤„ç†ç« èŠ‚")
            sections_to_process = list(section_results.items())
        
        # æŒ‰é¡ºåºå¤„ç†æ¯ä¸ªç« èŠ‚
        for section_title, result in sections_to_process:
            if result is None:
                print(f"âš ï¸ ç« èŠ‚ '{section_title}' æœªæ‰¾åˆ°å¤„ç†ç»“æœ")
                continue
                
            content = self._get_section_content(section_title, result, stats)
            if content.strip():
                final_sections.append(content.strip())
        
        # ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£
        final_document = '\n\n'.join(final_sections)
        
        # æ¸…ç†æ–‡æ¡£æ ¼å¼
        final_document = self._clean_document_format(final_document)
        
        print(f"âœ… æ–‡æ¡£åˆå¹¶å®Œæˆï¼")
        print(f"   æ€»ç« èŠ‚æ•°: {stats['total_sections']}")
        print(f"   è·³è¿‡ç« èŠ‚: {stats['skipped_sections']}")
        print(f"   å¢å¼ºç« èŠ‚: {stats['enhanced_sections']}")
        print(f"   å¤±è´¥ç« èŠ‚: {stats['failed_sections']}")
        
        return final_document
    
    def _get_section_content(self, section_title: str, result: Dict[str, Any], stats: Dict[str, int]) -> str:
        """
        è·å–ç« èŠ‚å†…å®¹
        
        Args:
            section_title: ç« èŠ‚æ ‡é¢˜
            result: ç« èŠ‚å¤„ç†ç»“æœ
            stats: ç»Ÿè®¡ä¿¡æ¯
            
        Returns:
            str: ç« èŠ‚å†…å®¹
        """
        status = result.get('status', 'unknown')
        
        if status == 'skipped':
            # è·³è¿‡çš„ç« èŠ‚ä½¿ç”¨åŸå†…å®¹
            content = result.get('original_content', '')
            stats['skipped_sections'] += 1
            print(f"  â­ï¸ è·³è¿‡ç« èŠ‚: {section_title}")
            
        elif status == 'success':
            # æˆåŠŸçš„ç« èŠ‚ä½¿ç”¨å¢å¼ºå†…å®¹
            content = result.get('enhanced_content', result.get('original_content', ''))
            stats['enhanced_sections'] += 1
            print(f"  âœ¨ å¢å¼ºç« èŠ‚: {section_title}")
            
            # å¦‚æœæœ‰è¯æ®ç»“æœï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å¼•ç”¨ä¿¡æ¯
            evidence_results = result.get('evidence_results', [])
            if evidence_results:
                content = self._add_evidence_enhancements(content, evidence_results)
                
        else:
            # å¤±è´¥æˆ–æœªçŸ¥çŠ¶æ€çš„ç« èŠ‚ä½¿ç”¨åŸå†…å®¹
            content = result.get('original_content', f"## {section_title}\n\nå¤„ç†å¤±è´¥")
            stats['failed_sections'] += 1
            print(f"  âš ï¸ å¤±è´¥ç« èŠ‚: {section_title}")
        
        return content
    
    def _add_evidence_enhancements(self, content: str, evidence_results: List[Dict[str, Any]]) -> str:
        """
        ä¸ºå†…å®¹æ·»åŠ è¯æ®å¢å¼º
        
        Args:
            content: åŸå§‹å†…å®¹
            evidence_results: è¯æ®ç»“æœåˆ—è¡¨
            
        Returns:
            str: å¢å¼ºåçš„å†…å®¹
        """
        # è¿™é‡Œå¯ä»¥æ ¹æ®è¯æ®ç»“æœå¯¹å†…å®¹è¿›è¡Œå¢å¼º
        # ä¾‹å¦‚æ·»åŠ å¼•ç”¨ã€æ•°æ®æ”¯æ’‘ç­‰
        enhanced_content = content
        
        for evidence in evidence_results:
            if evidence.get('processing_status') == 'success':
                enhanced_text = evidence.get('enhanced_text', '')
                if enhanced_text and enhanced_text != evidence.get('claim_text', ''):
                    # å¦‚æœæœ‰å¢å¼ºæ–‡æœ¬ï¼Œå¯ä»¥æ›¿æ¢åŸæ–‡ä¸­çš„å¯¹åº”éƒ¨åˆ†
                    claim_text = evidence.get('claim_text', '')
                    if claim_text in enhanced_content:
                        enhanced_content = enhanced_content.replace(claim_text, enhanced_text)
        
        return enhanced_content
    
    def _clean_document_format(self, document: str) -> str:
        """
        æ¸…ç†æ–‡æ¡£æ ¼å¼
        
        Args:
            document: åŸå§‹æ–‡æ¡£
            
        Returns:
            str: æ¸…ç†åçš„æ–‡æ¡£
        """
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        cleaned = re.sub(r'\n{3,}', '\n\n', document)
        
        # ç¡®ä¿æ ‡é¢˜å‰åæœ‰é€‚å½“çš„ç©ºè¡Œ
        cleaned = re.sub(r'\n(#{1,6}\s)', r'\n\n\1', cleaned)
        cleaned = re.sub(r'^(#{1,6}\s)', r'\1', cleaned)  # æ–‡æ¡£å¼€å¤´çš„æ ‡é¢˜ä¸éœ€è¦å‰ç½®ç©ºè¡Œ
        
        # ç§»é™¤è¡Œå°¾ç©ºæ ¼
        lines = cleaned.split('\n')
        cleaned_lines = [line.rstrip() for line in lines]
        
        return '\n'.join(cleaned_lines).strip()
    
    def save_enhanced_document(self, document: str, output_path: str) -> str:
        """
        ä¿å­˜å¢å¼ºæ–‡æ¡£
        
        Args:
            document: æ–‡æ¡£å†…å®¹
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(document)
            
            print(f"âœ… å¢å¼ºæ–‡æ¡£å·²ä¿å­˜: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡æ¡£å¤±è´¥: {e}")
            raise
    
    def generate_evidence_analysis(self, section_results: Dict[str, Dict[str, Any]], 
                                 output_path: str, timestamp: str) -> str:
        """
        ç”Ÿæˆç®€åŒ–çš„è¯æ®åˆ†ææŠ¥å‘Šï¼šåªåŒ…å«è®ºæ–­å’Œè¯æ®ç»“æœ
        
        Args:
            section_results: ç« èŠ‚å¤„ç†ç»“æœ
            output_path: è¾“å‡ºè·¯å¾„
            timestamp: æ—¶é—´æˆ³
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        try:
            # æ”¶é›†æ‰€æœ‰ç« èŠ‚çš„è®ºæ–­å’Œè¯æ®ç»“æœ
            all_unsupported_claims = []
            all_evidence_results = []
            
            for section_title, result in section_results.items():
                # æ·»åŠ ç¼ºä¹è¯æ®æ”¯æ’‘çš„è®ºæ–­
                unsupported_claims = result.get('unsupported_claims', [])
                all_unsupported_claims.extend(unsupported_claims)
                
                # æ·»åŠ è¯æ®æœç´¢ç»“æœ
                evidence_results = result.get('evidence_results', [])
                all_evidence_results.extend(evidence_results)
            
            # ç®€åŒ–çš„åˆ†ææ•°æ®ï¼šåªåŒ…å«ä¸¤ä¸ªå­—æ®µ
            analysis_data = {
                'unsupported_claims': all_unsupported_claims,
                'evidence_results': all_evidence_results
            }
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… è¯æ®åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            print(f"   ğŸ“‹ è®ºæ–­æ€»æ•°: {len(all_unsupported_claims)}")
            print(f"   ğŸ” è¯æ®ç»“æœ: {len(all_evidence_results)}")
            
            return output_path
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆè¯æ®åˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
            raise


def main():
    """æµ‹è¯•ç›´æ¥æ–‡æ¡£åˆå¹¶å™¨"""
    print("ğŸ”§ ç›´æ¥æ–‡æ¡£åˆå¹¶å™¨æµ‹è¯•")
    
    # ç¤ºä¾‹ç« èŠ‚ç»“æœ
    sample_section_results = {
        "ä¸€ã€æ¦‚è¿°": {
            "status": "skipped",
            "original_content": "# ä¸€ã€æ¦‚è¿°\n\nè¿™æ˜¯æ¦‚è¿°ç« èŠ‚çš„å†…å®¹ã€‚",
            "processing_time": 0,
            "statistics": {"claims_detected": 0, "evidence_found": 0, "claims_enhanced": 0}
        },
        "ï¼ˆä¸€ï¼‰é¡¹ç›®æ¦‚å†µ": {
            "status": "success",
            "original_content": "## ï¼ˆä¸€ï¼‰é¡¹ç›®æ¦‚å†µ\n\nè¿™æ˜¯é¡¹ç›®æ¦‚å†µçš„åŸå§‹å†…å®¹ã€‚",
            "enhanced_content": "## ï¼ˆä¸€ï¼‰é¡¹ç›®æ¦‚å†µ\n\nè¿™æ˜¯é¡¹ç›®æ¦‚å†µçš„å¢å¼ºå†…å®¹ï¼ŒåŒ…å«äº†æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚",
            "processing_time": 2.5,
            "statistics": {"claims_detected": 2, "evidence_found": 3, "claims_enhanced": 2},
            "evidence_results": [
                {
                    "claim_text": "åŸå§‹è®ºæ–­",
                    "enhanced_text": "å¢å¼ºåçš„è®ºæ–­",
                    "processing_status": "success",
                    "evidence_sources": ["æ¥æº1", "æ¥æº2"]
                }
            ]
        }
    }
    
    # æµ‹è¯•åˆå¹¶
    merger = DirectDocumentMerger()
    document = merger.merge_sections_to_markdown(sample_section_results)
    
    print(f"\nğŸ“„ ç”Ÿæˆçš„æ–‡æ¡£:")
    print("=" * 50)
    print(document)
    print("=" * 50)


if __name__ == "__main__":
    main()

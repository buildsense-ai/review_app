"""
è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥ä¸»è¿è¡Œè„šæœ¬

æä¾›å®Œæ•´çš„è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥æµç¨‹ï¼š
1. æå–æ ¸å¿ƒè®ºç‚¹
2. æ£€æŸ¥å„ç« èŠ‚ä¸æ ¸å¿ƒè®ºç‚¹çš„ä¸€è‡´æ€§
3. ä¿®æ­£ä¸ä¸€è‡´çš„ç« èŠ‚
4. ç”Ÿæˆä¿®æ­£åçš„æ–‡æ¡£
"""

import json
import logging
import sys
import os
from typing import Optional, List
from datetime import datetime

# å¯¼å…¥ç›¸å…³æ¨¡å—
from thesis_extractor import ThesisExtractor, ThesisStatement
from thesis_consistency_checker import ThesisConsistencyChecker, ConsistencyAnalysis
from document_regenerator import ThesisDocumentRegenerator
from config import config


def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    log_level = getattr(logging, config.log_level.upper(), logging.INFO)
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler(config.log_file, encoding=config.output_encoding)
        ]
    )


class ThesisConsistencyPipeline:
    """è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥æµæ°´çº¿ - ç®€åŒ–ä¸º3æ­¥æµç¨‹"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµæ°´çº¿"""
        self.extractor = ThesisExtractor()
        self.checker = ThesisConsistencyChecker()
        self.regenerator = ThesisDocumentRegenerator()
        self.logger = logging.getLogger(__name__)
    
    def run_full_pipeline(self, document_file: str, document_title: Optional[str] = None, 
                         output_dir: str = "./thesis_outputs", 
                         auto_correct: bool = True) -> dict:
        """
        è¿è¡Œç®€åŒ–çš„è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥æµæ°´çº¿ï¼ˆ3æ­¥æµç¨‹ï¼‰
        
        Args:
            document_file: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
            document_title: æ–‡æ¡£æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
            output_dir: è¾“å‡ºç›®å½•
            auto_correct: æ˜¯å¦è‡ªåŠ¨ä¿®æ­£é—®é¢˜ï¼ˆé»˜è®¤Trueï¼‰
            
        Returns:
            dict: æµæ°´çº¿æ‰§è¡Œç»“æœ
        """
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # å¦‚æœæ²¡æœ‰æä¾›æ ‡é¢˜ï¼Œä½¿ç”¨æ–‡ä»¶å
            if document_title is None:
                document_title = os.path.basename(document_file)
            
            self.logger.info(f"ğŸš€ å¼€å§‹è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥æµæ°´çº¿: {document_title}")
            
            # ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ–‡æ¡£å†…å®¹
            document_content = self._load_document_content(document_file)
            if not document_content:
                return {'error': 'æ— æ³•åŠ è½½æ–‡æ¡£å†…å®¹'}
            
            # ç¬¬äºŒæ­¥ï¼šæå–æ ¸å¿ƒè®ºç‚¹
            self.logger.info("ğŸ“‹ ç¬¬ä¸€æ­¥ï¼šæå–æ ¸å¿ƒè®ºç‚¹")
            thesis_statement = self.extractor.extract_thesis_from_document(document_content, document_title)
            
            if not thesis_statement.main_thesis:
                return {'error': 'æ— æ³•æå–æœ‰æ•ˆçš„æ ¸å¿ƒè®ºç‚¹'}
            
            # ä¸ä¿å­˜è®ºç‚¹æå–ç»“æœå’ŒæŠ¥å‘Šï¼ˆç®€åŒ–è¾“å‡ºï¼‰
            
            self.logger.info(f"âœ… æ ¸å¿ƒè®ºç‚¹æå–å®Œæˆ: {thesis_statement.main_thesis[:100]}...")
            
            # ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥è®ºç‚¹ä¸€è‡´æ€§
            self.logger.info("ğŸ” ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥è®ºç‚¹ä¸€è‡´æ€§")
            consistency_analysis = self.checker.check_consistency(document_content, thesis_statement, document_title)
            
            # ä¿å­˜ä¸€è‡´æ€§åˆ†æç»“æœï¼ˆä½¿ç”¨å†…ç½®æ—¶é—´æˆ³ç”Ÿæˆï¼‰
            consistency_file = self.checker.save_consistency_analysis(
                consistency_analysis, thesis_statement, document_title,
                output_dir  # åªä¼ é€’ç›®å½•ï¼Œè®©æ–¹æ³•è‡ªå·±ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            )
            
            # ä¸ç”Ÿæˆä¸€è‡´æ€§æŠ¥å‘Šï¼ˆç®€åŒ–è¾“å‡ºï¼‰
            
            self.logger.info(f"âœ… ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆï¼Œå‘ç° {consistency_analysis.total_issues_found} ä¸ªé—®é¢˜")
            
            # ç¬¬ä¸‰æ­¥ï¼šä¿®æ­£é—®é¢˜ç« èŠ‚å¹¶ç”Ÿæˆå®Œæ•´æ–‡æ¡£ï¼ˆå¦‚æœéœ€è¦ä¸”å¯ç”¨è‡ªåŠ¨ä¿®æ­£ï¼‰
            complete_document_results = None
            
            if consistency_analysis.total_issues_found > 0 and auto_correct:
                self.logger.info("ğŸ”§ ç¬¬ä¸‰æ­¥ï¼šä¿®æ­£é—®é¢˜ç« èŠ‚å¹¶ç”Ÿæˆå®Œæ•´æ–‡æ¡£")
                
                complete_document_results = self.regenerator.regenerate_complete_document(
                    analysis_file=consistency_file,
                    document_file=document_file,
                    output_dir=output_dir
                )
                
                if 'error' not in complete_document_results and 'message' not in complete_document_results:
                    self.logger.info(f"âœ… å®Œæ•´æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼Œä¿®æ­£äº† {complete_document_results.get('sections_count', 0)} ä¸ªç« èŠ‚")
                else:
                    self.logger.warning(f"âš ï¸ å®Œæ•´æ–‡æ¡£ç”Ÿæˆç»“æœ: {complete_document_results}")
            elif consistency_analysis.total_issues_found == 0:
                self.logger.info("âœ… æ–‡æ¡£è®ºç‚¹ä¸€è‡´æ€§è‰¯å¥½ï¼Œæ— éœ€ä¿®æ­£")
            else:
                self.logger.info("â„¹ï¸ å‘ç°é—®é¢˜ä½†æœªå¯ç”¨è‡ªåŠ¨ä¿®æ­£ï¼Œè¯·æ‰‹åŠ¨å¤„ç†")
            
            # ä¸ç”Ÿæˆæµæ°´çº¿æ‘˜è¦æŠ¥å‘Šï¼ˆç®€åŒ–è¾“å‡ºï¼‰
            
            # è¿”å›ç»“æœ
            result = {
                'status': 'success',
                'document_title': document_title,
                'thesis_statement': thesis_statement,
                'consistency_analysis': consistency_analysis,
                'complete_document_results': complete_document_results,
                'output_files': {
                    'consistency_analysis': consistency_file
                }
            }
            
            # æ·»åŠ å®Œæ•´æ–‡æ¡£è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
            if complete_document_results and 'saved_files' in complete_document_results:
                result['output_files'].update(complete_document_results['saved_files'])
            
            self.logger.info("ğŸ‰ è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥æµæ°´çº¿æ‰§è¡Œå®Œæˆ")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
            return {'error': f'æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {str(e)}'}
    
    def _load_document_content(self, document_file: str) -> str:
        """
        åŠ è½½æ–‡æ¡£å†…å®¹
        
        Args:
            document_file: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: æ–‡æ¡£å†…å®¹
        """
        try:
            if document_file.endswith('.json'):
                # å¤„ç†JSONæ–‡æ¡£ï¼Œæå–generated_content
                with open(document_file, 'r', encoding='utf-8') as f:
                    json_data = json.load(f)
                
                content_parts = []
                report_guide = json_data.get('report_guide', [])
                
                for part in report_guide:
                    sections = part.get('sections', [])
                    
                    for section in sections:
                        subtitle = section.get('subtitle', '')
                        generated_content = section.get('generated_content', '')
                        if subtitle and generated_content:
                            content_parts.append(f"## {subtitle}\n\n{generated_content}")
                
                content = "\n\n".join(content_parts)
                self.logger.info(f"æˆåŠŸåŠ è½½JSONæ–‡æ¡£ï¼Œæå–äº†{len(content_parts)}ä¸ªç« èŠ‚")
                return content
            else:
                # å¤„ç†Markdownæ–‡æ¡£
                with open(document_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                self.logger.info(f"æˆåŠŸåŠ è½½Markdownæ–‡æ¡£")
                return content
        except Exception as e:
            self.logger.error(f"åŠ è½½æ–‡æ¡£å¤±è´¥: {e}")
            return ""
    
    def _generate_pipeline_summary(self, document_title: str, thesis_statement: ThesisStatement, 
                                 consistency_analysis: ConsistencyAnalysis, 
                                 correction_results: Optional[dict]) -> str:
        """
        ç”Ÿæˆæµæ°´çº¿æ‘˜è¦æŠ¥å‘Š
        
        Args:
            document_title: æ–‡æ¡£æ ‡é¢˜
            thesis_statement: æ ¸å¿ƒè®ºç‚¹ç»“æ„
            consistency_analysis: ä¸€è‡´æ€§åˆ†æç»“æœ
            correction_results: ä¿®æ­£ç»“æœï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: æ‘˜è¦æŠ¥å‘Šå†…å®¹
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        report_lines = [
            f"# è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥æµæ°´çº¿æ‘˜è¦æŠ¥å‘Š",
            f"",
            f"**æ–‡æ¡£æ ‡é¢˜**: {document_title}",
            f"**æ‰§è¡Œæ—¶é—´**: {timestamp}",
            f"",
            f"## ğŸ¯ æ ¸å¿ƒè®ºç‚¹æå–ç»“æœ",
            f"**ä¸»è¦è®ºç‚¹**: {thesis_statement.main_thesis}",
            f"",
            f"**æ”¯æ’‘è®ºæ®**:",
        ]
        
        for i, arg in enumerate(thesis_statement.supporting_arguments, 1):
            report_lines.append(f"{i}. {arg}")
        
        report_lines.extend([
            f"",
            f"**å…³é”®æ¦‚å¿µ**: {', '.join(thesis_statement.key_concepts)}",
            f"",
            f"## ğŸ” ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ",
            f"**æ•´ä½“ä¸€è‡´æ€§è¯„åˆ†**: {consistency_analysis.overall_consistency_score:.2f}/1.00",
            f"**å‘ç°é—®é¢˜æ€»æ•°**: {consistency_analysis.total_issues_found}",
            f""
        ])
        
        if consistency_analysis.total_issues_found == 0:
            report_lines.append("âœ… **ä¼˜ç§€**: æ‰€æœ‰ç« èŠ‚éƒ½ä¸æ ¸å¿ƒè®ºç‚¹ä¿æŒè‰¯å¥½ä¸€è‡´æ€§")
        else:
            report_lines.append("âš ï¸ **å‘ç°é—®é¢˜**: ä»¥ä¸‹ç« èŠ‚å­˜åœ¨ä¸€è‡´æ€§é—®é¢˜")
            for issue in consistency_analysis.consistency_issues:
                report_lines.append(f"- {issue.section_title} ({issue.issue_type})")
        
        report_lines.append("")
        
        # ä¿®æ­£ç»“æœ
        if correction_results:
            if 'error' in correction_results:
                report_lines.extend([
                    f"## âŒ ç« èŠ‚ä¿®æ­£ç»“æœ",
                    f"ä¿®æ­£è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {correction_results['error']}",
                    f""
                ])
            elif 'message' in correction_results:
                report_lines.extend([
                    f"## â„¹ï¸ ç« èŠ‚ä¿®æ­£ç»“æœ",
                    f"{correction_results['message']}",
                    f""
                ])
            else:
                report_lines.extend([
                    f"## ğŸ”§ ç« èŠ‚ä¿®æ­£ç»“æœ",
                    f"**ä¿®æ­£ç« èŠ‚æ•°**: {len(correction_results)}",
                    f"**ä¿®æ­£ç« èŠ‚åˆ—è¡¨**:",
                ])
                
                for section_title, result in correction_results.items():
                    original_issue = result.get('original_issue', {})
                    report_lines.append(f"- {section_title} (åŸé—®é¢˜: {original_issue.get('issue_type', '')})")
                
                report_lines.append("")
        else:
            if consistency_analysis.total_issues_found > 0:
                report_lines.extend([
                    f"## â„¹ï¸ ç« èŠ‚ä¿®æ­£ç»“æœ",
                    f"æœªæ‰§è¡Œè‡ªåŠ¨ä¿®æ­£ï¼Œè¯·æ‰‹åŠ¨å¤„ç†å‘ç°çš„ä¸€è‡´æ€§é—®é¢˜",
                    f""
                ])
        
        # å»ºè®®
        report_lines.extend([
            f"## ğŸ’¡ æ”¹è¿›å»ºè®®",
        ])
        
        for suggestion in consistency_analysis.improvement_suggestions:
            report_lines.append(f"- {suggestion}")
        
        report_lines.extend([
            f"",
            f"## ğŸ“ è¾“å‡ºæ–‡ä»¶",
            f"- æ ¸å¿ƒè®ºç‚¹æå–ç»“æœ: `thesis_statement_{document_title}.json`",
            f"- æ ¸å¿ƒè®ºç‚¹æŠ¥å‘Š: `thesis_report_{document_title}.md`",
            f"- ä¸€è‡´æ€§åˆ†æç»“æœ: `consistency_analysis_{document_title}.json`",
            f"- ä¸€è‡´æ€§æ£€æŸ¥æŠ¥å‘Š: `consistency_report_{document_title}.md`",
        ])
        
        if correction_results and 'error' not in correction_results and 'message' not in correction_results:
            report_lines.extend([
                f"- ä¿®æ­£åç« èŠ‚å†…å®¹: `corrected_sections_*.json`",
                f"- ä¿®æ­£åç« èŠ‚æŠ¥å‘Š: `corrected_sections_*.md`",
            ])
        
        report_lines.extend([
            f"",
            f"---",
            f"*æœ¬æŠ¥å‘Šç”±Gauzè®ºç‚¹ä¸€è‡´æ€§Agentè‡ªåŠ¨ç”Ÿæˆ*"
        ])
        
        return "\n".join(report_lines)


def analyze_document_from_file(file_path: str, document_title: Optional[str] = None, 
                             output_dir: str = "./thesis_outputs",
                             auto_correct: bool = True):
    """
    ä»æ–‡ä»¶è¯»å–æ–‡æ¡£å†…å®¹å¹¶è¿›è¡Œå®Œæ•´çš„è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥
    
    Args:
        file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
        document_title: æ–‡æ¡£æ ‡é¢˜ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æ–‡ä»¶åï¼‰
        output_dir: è¾“å‡ºç›®å½•
        auto_correct: æ˜¯å¦è‡ªåŠ¨ä¿®æ­£é—®é¢˜ï¼ˆé»˜è®¤Trueï¼‰
        
    Returns:
        åˆ†æç»“æœ
    """
    try:
        # å¦‚æœæ²¡æœ‰æä¾›æ ‡é¢˜ï¼Œä½¿ç”¨æ–‡ä»¶å
        if document_title is None:
            document_title = os.path.basename(file_path)
        
        # åˆ›å»ºæµæ°´çº¿å¹¶æ‰§è¡Œ
        pipeline = ThesisConsistencyPipeline()
        result = pipeline.run_full_pipeline(
            document_file=file_path,
            document_title=document_title,
            output_dir=output_dir,
            auto_correct=auto_correct
        )
        
        return result
        
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        return None
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return None


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    setup_logging()
    
    # é»˜è®¤é…ç½®
    default_file_path = "final_markdown_merged_document_20250828_160506.md"
    default_output_dir = "./test_results"
    
    # å¦‚æœæ²¡æœ‰æä¾›å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    if len(sys.argv) < 2:
        print("ğŸš€ ä½¿ç”¨é»˜è®¤é…ç½®è¿è¡Œè®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥")
        print(f"ğŸ“„ é»˜è®¤æ–‡æ¡£: {default_file_path}")
        print(f"ğŸ“ é»˜è®¤è¾“å‡ºç›®å½•: {default_output_dir}")
        print("")
        print("å¦‚éœ€è‡ªå®šä¹‰é…ç½®ï¼Œä½¿ç”¨æ–¹æ³•:")
        print("  python run_thesis_checker.py <æ–‡æ¡£æ–‡ä»¶è·¯å¾„> [é€‰é¡¹]")
        print("")
        print("é€‰é¡¹:")
        print("  --title <æ ‡é¢˜>          æŒ‡å®šæ–‡æ¡£æ ‡é¢˜")
        print("  --output <ç›®å½•>         æŒ‡å®šè¾“å‡ºç›®å½•")
        print("  --no-auto-correct      ä¸è‡ªåŠ¨ä¿®æ­£é—®é¢˜ï¼Œåªè¿›è¡Œæ£€æŸ¥")
        print("")
        
        # ä½¿ç”¨é»˜è®¤é…ç½®
        file_path = default_file_path
        document_title = "ç”¨æˆ·æ‰‹å†Œæ–‡æ¡£"
        output_dir = default_output_dir
        auto_correct = True
    else:
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        file_path = sys.argv[1]
        document_title = None
        output_dir = default_output_dir  # é»˜è®¤ä½¿ç”¨ test_results
        auto_correct = True
    
        i = 2
        while i < len(sys.argv):
            if sys.argv[i] == '--title' and i + 1 < len(sys.argv):
                document_title = sys.argv[i + 1]
                i += 2
            elif sys.argv[i] == '--output' and i + 1 < len(sys.argv):
                output_dir = sys.argv[i + 1]
                i += 2
            elif sys.argv[i] == '--no-auto-correct':
                auto_correct = False
                i += 1
            else:
                print(f"æœªçŸ¥é€‰é¡¹: {sys.argv[i]}")
                return
    
    print(f"ğŸ” å¼€å§‹è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥: {file_path}")
    if document_title:
        print(f"ğŸ“‹ æ–‡æ¡£æ ‡é¢˜: {document_title}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    if not auto_correct:
        print("â„¹ï¸ ä»…æ£€æŸ¥æ¨¡å¼ï¼Œä¸è‡ªåŠ¨ä¿®æ­£")
    
    # æ‰§è¡Œåˆ†æ
    result = analyze_document_from_file(
        file_path=file_path,
        document_title=document_title,
        output_dir=output_dir,
        auto_correct=auto_correct
    )
    
    if result is None:
        print("âŒ è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥")
        return
    
    if 'error' in result:
        print(f"âŒ é”™è¯¯: {result['error']}")
        return
    
    # æ˜¾ç¤ºç»“æœæ‘˜è¦
    print(f"\nğŸ“Š è®ºç‚¹ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆ:")
    print(f"   æ ¸å¿ƒè®ºç‚¹: {result['thesis_statement'].main_thesis[:100]}...")
    print(f"   ä¸€è‡´æ€§è¯„åˆ†: {result['consistency_analysis'].overall_consistency_score:.2f}")
    print(f"   å‘ç°é—®é¢˜: {result['consistency_analysis'].total_issues_found} ä¸ª")
    
    if result.get('complete_document_results'):
        complete_results = result['complete_document_results']
        if 'error' in complete_results:
            print(f"   å®Œæ•´æ–‡æ¡£ç”Ÿæˆ: å¤±è´¥ - {complete_results['error']}")
        elif 'message' in complete_results:
            print(f"   å®Œæ•´æ–‡æ¡£ç”Ÿæˆ: {complete_results['message']}")
        else:
            print(f"   å®Œæ•´æ–‡æ¡£ç”Ÿæˆ: æˆåŠŸï¼Œä¿®æ­£äº† {complete_results.get('sections_count', 0)} ä¸ªç« èŠ‚")
            if 'saved_files' in complete_results:
                print(f"   å®Œæ•´ä¿®æ­£åæ–‡æ¡£: {complete_results['saved_files'].get('complete_document', 'æœªç”Ÿæˆ')}")
    
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜åˆ°: {output_dir}")
    print(f"   ä¸€è‡´æ€§åˆ†æ: {result['output_files']['consistency_analysis']}")
    if result.get('complete_document_results') and 'saved_files' in result['complete_document_results']:
        complete_doc = result['complete_document_results']['saved_files'].get('complete_document')
        if complete_doc:
            print(f"   ä¿®æ­£åæ–‡æ¡£: {complete_doc}")


if __name__ == "__main__":
    main()
